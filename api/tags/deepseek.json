{"name":"deepseek","slug":"deepseek","count":1,"postlist":[{"title":"DeepSeek 模型原理解析（重点：MoE 架构）","uid":"9b46d1c5a75e2d41735eee2edeede3f3","slug":"deepseek_moe","date":"2025-08-22T16:00:00.000Z","updated":"2025-08-23T01:54:16.639Z","comments":true,"path":"api/articles/deepseek_moe.json","keywords":"blog, technology, programming","cover":"images/deepseek_moe.png","text":"面向具有一定深度学习基础的读者，本文系统解析 DeepSeek 系列模型的原理与设计特点，重点关注其 Mixture-of-Experts (MoE) 稀疏架构...","permalink":"/post/deepseek_moe","photos":[],"count_time":{"symbolsCount":"3.7k","symbolsTime":"3 mins."},"categories":[{"name":"人工智能","slug":"人工智能","count":3,"path":"api/categories/人工智能.json"}],"tags":[{"name":"deepseek","slug":"deepseek","count":1,"path":"api/tags/deepseek.json"},{"name":"MoE","slug":"MoE","count":1,"path":"api/tags/MoE.json"}],"author":{"name":"Rockway","slug":"blog-author","avatar":"https://lingmafuture.github.io/images/3.jpg","link":"https://lingmafuture.github.io","description":"一个充满情怀的AI技术探索者，欢迎交流人工智能、量化交易、创业灵感。","socials":{"github":"https://github.com/lingmafuture","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}]}